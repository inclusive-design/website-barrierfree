
<html>
<head>
<title>CANARIE: Appendix A - Evaluation</title>

<STYLE TYPE="text/css">
<!--

H2 { margin-top: 10px; font-family: verdana, sans-serif; color: #003366; font-size: 16;text-align: center; width: 65%; }
H2.sub { margin-left: 10px; font-family: verdana, sans-serif; color: #003366; font-size: 16;text-align: left }
H3 { color: #c47900; font-size: 15; font-variant: small-caps; width: 65%; } 
H4 { margin-left: 10px; font-family: verdana, sans-serif; color: #003366; font-size: 14;  }
h4.blu { margin-left: 10px; background-color: #003366; margin-left: 10px; font-family: verdana, sans-serif; color: #FFFFFF; font-size: 12;  width: 65%; }

p  { margin-left: 10px; font-family: verdana, sans-serif; font-size: 12; text-align: justify; width: 65%;}
p.table  { font-family: verdana, sans-serif; font-size: 12; style: bold;}

ul { margin-left: 25px; list-style-type:square; font-family: verdana, sans-serif; font-size: 12; text-align: justify; width: 55%;}

ol { margin-left: 25px; list-style-type:square; font-family: verdana, sans-serif; font-size: 12; text-align: justify; width: 55%;}

a { margin-center: 10px; font-family: verdana, sans-serif; color: #003366; font-size: 12;}
a:hover {color: #c47900;text-decoration: underline; }


div { text-align: center; width: 65%;} 
i { margin-left: 10px; font-family: times; color: #003366; font-size: 12;}
i .caption { margin-center: 10px; font-family: times; font-size: 11;text-align: center;}

table { margin-left: 10px; font-family: verdana, sans-serif;  font-size: 10;text-align: center; width: 65%;}
tr.heading {background-color: #003366; font-family: verdana, sans-serif; color: #ffffff; text-align: center; valign: top;}


-->
</STYLE>
</head>


<body bgcolor=#ffffff>
<a name="top"></a>
<h2>Creating Barrier-Free, Broadband Learning Environments </h2>
<h4 class="blu">Appendix A: Evaluation Report</h4>
<h4>CANARIE Project: Broadband Access to Education</h4>
<a href="../report.html"><i>Evaluation Team Final Report</i> </a>
<p><font size="-1">September 2002</font></p>
<h4>Introduction</h4>
<p>Advances in information and communication technology (ICT) have changed radically 
  the way individuals share, access and process information. Those with access 
  to ICT are able to share, search and store digitized information at high speeds 
  across distances that may span the globe. Large amounts of information on an 
  enormous variety of topics and from many different points of view can be easily 
  and inexpensively distributed and acquired. ICT also offers opportunities for 
  users to interact with the information and its authors in ways that can be much 
  faster and simpler than other forms of communication. </p>
<p>The capabilities of these new technologies can provide a viable alternative 
  to traditional distance education methods such as televised lectures, correspondence, 
  and electronic conferences and even to traditional school-based education. ICT 
  is poised to play a revolutionary role in how institutions, educators and learners 
  approach distance education and learning. There are also important opportunities 
  to provide distance education services to people who have excluded from these 
  traditional forms because of a lack of means to access the materials. ICT allows 
  information to be prepared and presented with alternative input and output technologies 
  to accommodate individual requirements. In addition, interaction strategies 
  can be designed to accommodate the needs of individuals rather than being prepared 
  for one delivery technique such as printed text. However, it is important that 
  access for people with disabilities be considered at the beginning of designing 
  ICT-based learning systems so that a variety of learner needs and abilities 
  can be included. </p>
<p>The Creating Barrierfree Access to Learning Environments initiative provided 
  a customizable ICT environment for on-line, video-based learning material. This 
  system allows individuals to select the method and alternative display methods. 
  For example, learners could select closed captions to be shown along with the 
  video. Users also had control over caption colour, background colour and location 
  of the captions on the display. In addition, further information that related 
  to the video-based learning material could be added such as links within closed 
  captions, and text or graphical annotations for further explanation of the existing 
  material.</p>
<p>This report provides a description of various ICT related systems and issues 
  of access on the stakeholders in education. A complete description of the Barrier-free 
  system can be found in section 2. The results of a series of evaluations related 
  to access and ICT in general, and then to the barrier-free system are presented. 
</p>

<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>The Classroom</i></p>
<p>The traditional classroom involves an expert teacher and a community of learners. 
  In the constructivist tradition, new knowledge is created as the teacher and 
  learners share information. Until recently, however, creating a community of 
  learners in the distance education mode was difficult and even unlikely. Instead, 
  in this mode, learning was usually a solitary process. Online education can 
  remove the barriers of separation and potential isolation amongst learners and 
  educators; it can provide opportunities for both synchronous and asynchronous 
  learning that can allow the formation of an on-line community of learners. (synchronous 
  learning takes place amongst learners at the same time (i.e. online conference) 
  and asynchronous learning occurs at different times such as with a bulletin 
  board discussion). This online community of learners is different than the community 
  of learners formed with traditional classroom environments. Olsen, Olsen &amp; 
  Meader (1995) and Hiltz et. al (1985) suggest that each technology (e.g., traditional 
  telephony, email and video conferencing) is distinctive by the nature of the 
  medium from which it is constituted. Each method of delivery has particular 
  strengths and weaknesses; some of which are due to the technologies employed. 
  The goal in using a particular technology is not to replicate identically that 
  which can be easily achieved when learners are face-to-face. Rather, it is to 
  find ways to allow participants to achieve all the interactions that are necessary 
  to complete the defined task in a productively and efficiently. It is the properties 
  of the medium that contribute to these unique experiences and influence the 
  impact of the various factors on the success of task completion and the formation 
  of the online community of learners.</p>
<p>Essentially, ICT reduces the distance in distance education but it still cannot 
  be considered identical to same place/same time teaching. Instead, one could 
  think of online learning as a classroom in which each individual is separated 
  by a rice paper wall. Communication is possible through the wall and one might 
  even be able to see the instructor or other students yet a separation exists 
  albeit a barely tangible one. </p>
<p>Learning in the rice paper classroom is comparable to the traditional classroom 
  and in some cases better than learning in the traditional classroom (Schutte, 
  J.G. 2001, Schoech, D. 2000). Schutte (2001) found that students in an online 
  statistics course taught completely over the World Wide Web, scored an average 
  of 20% higher than students learning the same subject in a traditional class 
  in mid-term and final examinations. Furthermore, the virtual class had a significantly 
  higher perceived peer contact, time spent on class work and understanding of 
  the material at semester end than the traditional class. It is important to 
  note that the online students in this study received two face-to-face sessions 
  of instructions on using the relevant technology for the course (i.e. email, 
  and Internet Relay Chat). While many Web-based courses have self-selected participants 
  who may possess the knowledge and desire to use technology necessary to participate 
  successfully in the course; provision must be made within the online course 
  for students who do not have this skill (Thomson, J.S., Stringer, S.B., 1998). 
</p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a> 
</p>
<p><i>The Educator</i></p>
<p>Taking education online will change the role of the educator (Sweet, 2000, 
  Belanger &amp; Jordan, 2000, Baumgartner, P. &amp; Payre, S., 1998). How these 
  changes will come about and what changes we may expect are difficult to predict. 
  It is clear that virtual classrooms tend to be more learner-driven than the 
  traditional classroom (Schoech, 2000, Grubbs, L, &amp; Lockey, Mick, 2000, Wallace, 
  E. &amp; Smythe D., 1999, Dooley, K.E., Edmundson, C., Hobaugh, C., 1997). This 
  trend may be related to the flexibility of the online course as well as the 
  ease of peer contact and thoughtful discussion permitted by asynchronous communication 
  tools such as bulletin boards and email. Some suggest that traditional face-to-face 
  learning could become obsolete as computer assisted learning becomes more popular 
  and cost-effective (Schoech, 2000, Sweet, 2000, Belanger &amp; Jordan, 2000).</p>
<p>While online learning increases flexibility for the learner, the opposite seems 
  to occur for the instructor particularly if the course includes synchronous 
  chats. Most instructors report increased time demands in both the preparation 
  and mediation of their online course (Schoech, 2000,). For example, Instructors 
  may find that the amount of correspondence with students alone creates a heavy 
  workload (Schoech, 2000). Training in managing the communication technology 
  may be necessary for the online instructor.</p>
<p>Certainly, the instructor (if there is one) for an online course will need 
  to have training in courseware, relevant technology and online mediation (Wallace 
  &amp; Smythe, 1999, Thomson, Stringer &amp; Sharon, 1998). Finally, development 
  &amp; delivery of the web-based course requires collaboration between the instructor, 
  content providers, developers and technology support staff. These collaborations 
  may be a challenge to instructors who are accustomed to developing courses on 
  their own.</p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>The Institution</i></p>
<p>The role of the institution also changes with the increase in web distance 
  learning (WDL). Indeed, the physical entity of the institution may not be necessary 
  to learners and instructors as is evidenced by the International University 
  (IU) an independent, non-profit, &laquo;virtual university&raquo; that offers 
  bachelor and master degrees in business communication only through online courses 
  (Zuniga, R.E. &amp; Pease, P., 1998). Institutions of higher education that 
  traditionally draw from local populations may see this demographic change as 
  local students become able to attend distant schools via the Internet while 
  maintaining the financial benefits of living at home with parents. At the same 
  time, some institutions will have a growing distance education population that 
  will have different needs and expectations from the local student population. 
  For example, access to resources such as journal articles and databases via 
  the Internet. </p>
<p><i>The Learner</i></p>
<p>We have already discussed that the learner typically drives learning in the 
  virtual classroom and that the learner, through online distance education, may 
  have access to learning that is equal to that of the on-campus student. Access 
  to online distance education, however, presumes that the student is able to 
  finance the technology investment required to participate successfully in the 
  program. Even with the trend towards improved technology at lower cost, this 
  investment may be unwieldy for students especially the recurring costs related 
  to having a high-speed or broadband internet service provider (ISP). </p>
<p>Students in one study of an online course reported that class discussions were 
  far richer than that in face-to-face classrooms (Schoech, 2000). Similarly, 
  all but one of the 70 respondents to a survey of IU students agreed with the 
  statement, &laquo;I would recommend that others take a course that: uses electronic 
  communication . . . &raquo; (Zuniga &amp; Pease, 1998). One explanation for 
  this difference is the flexibility of time permitted to online students particularly 
  in asynchronous discussions in which the student has time to reflect, research 
  and compose their thoughts before sharing them with the class in digitized form. 
  Other studies have shown that students in a virtual class spent significantly 
  more time on class and had a significantly higher positive affect towards the 
  course content than students of the same course in a traditional setting (Schutte, 
  2000). </p>
<p>Like educators, students must also possess the requisite technology skills 
  in order to take full advantage of an online course. In order for delivery of 
  an online course to be successful, the technical competency and support available 
  to the student must be considered (Thomson &amp; Stringer, 1998). Indeed, some 
  students may require training in order to be effective participants in web-based 
  education (Schutte, 2000, Thomson &amp; Stringer, 1998). </p>
<p>A potential benefit of distance education is the potential to make online courses 
  completely accessible to all learners provided guidelines for accessible design 
  are followed and mandated. Creating accessible online education requires a two-pronged 
  approach that considers both learners and course developers. For learners, the 
  appropriate kind of accommodation must be determined. Broadband access provides 
  opportunity to provide information in novel ways such as multiple video or caption 
  tracks. The optimal way to present educational material to learners via these 
  new methods must be investigated. For course developers, information about how 
  to provide accessible content as well as reasonable access to accessible learning 
  materials must be provided. This project addressed these two aspects of accessible 
  learning. This section of the report details the activities of the evaluation 
  component of the project. </p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<h4>Evaluation</h4>
<p>Evaluation of the effectiveness of online courses may take into account many 
  factors that consider the role of the instructor, institution and learner as 
  well as the interaction between these three. Typically, these evaluations use 
  surveys and interviews to garner faculty and student perceptions of online courses 
  as well as student-oriented performance indicators such as tests and analysis 
  of complexity of online discussions (Schutte, 2000, Schoech, 2000, Belanger 
  &amp; Jordan, 2000, Zuniga &amp; Pease, 1998). </p>
<p>Variables that typically relate to faculty include:</p>
<ul>
  <li>Accessibility to students</li>
  <li>Workload</li>
  <li>Ease/training with technology</li>
  <li>Relationship to technical support</li>
  <li>Interaction with development team</li>
</ul>
<p>Variables that typically relate to the institution include:</p>
<ul>
  <li>Cost of implementation</li>
  <li>Technical support</li>
  <li>Course developers</li>
  <li>Online resources</li>
  <li> Changes in student pools/enrolment</li>
  <li> Effectiveness of curriculum</li>
</ul>
<p>Variables that typically relate to the student include:</p>
<ul>
  <li>Access to required technology</li>
  <li>Competency with required technology</li>
  <li>Access to resources 
  <li>Interaction with peers</li>
  <li>Interaction with instructors</li>
  <li>Understanding of content</li>
  <li>Control over learning process</li>
  <li>Performance Achievement of learning objectives</li>
</ul>
<p>The evaluations carried out in the Barrier-free project focused on variables 
  relating to the learner and to the course developer (who may or may not be the 
  course instructor). Learners were identified as individuals in a number of needs 
  groups such as hard of hearing, deaf, blind, low vision, learning disabled, 
  and general population. Course developers were identified as ranging in expertise 
  from professional course developer to educator with limited or no experience 
  with courseware. The evaluation was concerned with three aspects: usability, 
  optimal accommodations for learning and the repository model. A complete description 
  of the repository model can be found in section 2 the design final report.&nbsp; 
</p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a> 
</p>
<p><i>Usability and Evaluation Methods</i> <br />
  This project uses the wealth of human factors and usability testing methods 
  research available to carry out evaluations with the player and editor versions 
  of the Barrierfree environment. Usability factors such as ease of use, learning 
  and customizability, were seen as an important factors in the project&#39;s 
  success because the environment is intended to be highly interactive and users 
  must manage the software. User preferences, expectations and needs were therefore 
  considered in each phase of the evaluation.</p>
<p>There is a host of proven human design methodology for preparing for and addressing 
  end-user requirements. These published standard practices are also widely available 
  on the Internet.&nbsp; The following table is a sample of electronic resources 
  provided by leading experts and institutions in the field that were drawn on 
  for usability evaluation methods (UEMs) and metrics in this project.&nbsp; </p>
<table border="1" >
  <tr class="heading"> 
    <td>Resource Description</td>
    <td>URL</td>
  </tr>
  <tr> 
    <td>Compilation of Usability Resources and References <br />
      (Jeff Axup, 2002) </td>
    <td><a href="http://www.userdesign.com/usability.html%20">http://www.userdesign.com/usability.html 
      </a></td>
  </tr>
  <tr> 
    <td>Comparison of Usability Evaluation Methods (UEMs) <br />
      (based on Gray & Salzman, 1998) &nbsp;</td>
    <td><a href="http://www.userdesign.com/docs/uem_compare.html">http://www.userdesign.com/docs/uem_compare.html</a> 
      &nbsp;</td>
  </tr>
  <tr> 
    <td>Efficient & Inexpensive UEMs <br />
      (by Jacob Nielsen, 1994) &nbsp;</td>
    <td><a href="http://www.useit.com/papers/guerrilla_hci.html">http://www.useit.com/papers/guerrilla_hci.html</a> 
      &nbsp;</td>
  </tr>
  <tr> 
    <td>HCI Web resources from Online Computer Library Centre <br />
      (OCLC) &nbsp;</td>
    <td><a href="http://www.oclc.org/usability/resources/index.htm">http://www.oclc.org/usability/resources/index.htm&nbsp;</a></td>
  </tr>
  <tr> 
    <td>Heuristic Evaluation (Jakob Nielsen) &nbsp;</td>
    <td><a href="http://www.useit.com/papers/heuristic/">http://www.useit.com/papers/heuristic/</a>&nbsp;</td>
  </tr>
  <tr> 
    <td>How to Plan and Report a Usability Evaluation <br />
      (Seth Gordon, 2000) &nbsp;</td>
    <td><a href="http://builder.cnet.com/webbuilding/pages/Graphics/Evaluation/">http://builder.cnet.com/webbuilding/pages/Graphics/Evaluation/</a> 
      &nbsp;</td>
  </tr>
  <tr> 
    <td>Usability and Inspection Methods <br />
      (James Hom, 1998) &nbsp;</td>
    <td><a href="http://jthom.best.vwh.net/usability/">http://jthom.best.vwh.net/usability/</a> 
      &nbsp;</td>
  </tr>
  <tr> 
    <td>Usability Evaluation <br />
      (University of MD) &nbsp;</td>
    <td><a href="http://www.cs.umd.edu/%7Ezzj/UsabilityHome.html">http://www.cs.umd.edu/~zzj/UsabilityHome.html</a> 
      &nbsp;</td>
  </tr>
  <tr> 
    <td>Usability Evaluation Techniques <br />
      (Napier U, School of Computing) &nbsp;</td>
    <td><a href="http://www.dcs.napier.ac.uk/marble/Usability/Evaluation.html%20&amp;nbsp;">http://www.dcs.napier.ac.uk/marble/Usability/Evaluation.html 
      &nbsp;</a></td>
  </tr>
  <tr> 
    <td>Usability Metrics <br />
      (Napier U, School of Computing) l&nbsp;</td>
    <td><a href="http://www.dcs.napier.ac.uk/marble/Usability/UsabilityMetrics.htm">http://www.dcs.napier.ac.uk/marble/Usability/UsabilityMetrics.htm</a></td>
  </tr>
</table>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p>These resources augment the body of print-based research upon which the evaluation 
  methods for this project were built. The electronic resources are especially 
  useful for sharing of basic usability principles with team members so that issues 
  related to human-computer interaction (HCI) and user-needs were salient from 
  the outset. In addition to usability principles, usability evaluation methods 
  (UEMs) were used. One significant difficulty encountered with these conventional 
  UEMs was the lack of methodologies for users using alternative forms of accessing 
  software (e.g., using screen readers) and of communication (e.g., using a gestural 
  language to communicate). </p>
<p>An inclusive UEM for gestural language users was thus developed and investigated 
  as part of the project. The main activities of the evaluation team were as follows:</p>
<ul>
  <li> Review of literature on distance and online education</li>
  <li> Survey of distance educators</li>
  <li> Evaluation and development of novel American Sign Language (ASL) video 
    translation formats</li>
  <li> Heuristic evaluation of the course player</li>
  <li> Beta testing of course player</li>
  <li> Two phases of user testing for player</li>
  <li> Heuristic evaluation of the authoring tool</li>
  <li> User testing of authoring tool</li>
</ul>
<p>Along with reports and recommendations to the development team, the deliverables 
  from these activities include: </p>
<ul>
  <li> Education at a distance: Recommendations from Distance Educators. (paper 
    will be submitted to Journal for Distance Education)</li>
  <li> Methods for Inclusion: Employing Think Aloud Protocols with Individuals 
    Who are Dear (paper presented at International Conference on Computers Helping 
    People with Special Needs, 2002)</li>
  <li> Courseware: accommodations and usability testing methods for learners who 
    are deaf. (paper submitted to CHI 2003 Conference on Human Factors in Computing 
    Systems)</li>
  <li> Distance Educators Survey</li>
</ul>
<p>As part of the team’s background research into distance and online education, 
  a survey of best practices in distance education was developed and sent to 200 
  individuals identified as distance educators. The survey focused on best practices 
  and pitfalls of distance education as well as media used for delivery of distance 
  courses and accommodations employed for individuals with special needs. </p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>Evaluation Process</i><br />
  Our evaluation goal was to understand the criteria for successful distance education 
  and to assess the practices employed by educators to make their courses accessible 
  to all learners. A copy of the survey instrument that was developed by the evaluation 
  team is available on page Error! Bookmark not defined. of this report. </p>
<p><i>Methods</i> <br />
  The survey was emailed to two hundred educators identified through their participation 
  in conferences related technology and distance education. 78 of the recipients 
  responded to the investigators but only 33 completed the survey. The survey 
  consisted of open-ended and forced-choice questions that covered background 
  information, accessibility practices and recommendations. </p>
<p><i>Results</i> <br />
  The majority of respondents taught post-secondary or graduate level distance 
  education (DE) courses (see Table 1). On average, the respondents had developed 
  three distance courses, had taught distance education courses for three years 
  and had taught four distance courses at the time of the survey. </p>
<p><i>Analysis</i> <br />
  The survey responses were compiled and analysed in a variety of ways. Descriptives 
  and simple counts were used for the closed and background questions and a coding 
  system was developed for the three open-ended questions. Twenty-five percent 
  of the responses were coded by two individuals trained in the coding scheme 
  and an average intraclass correlation (ICC) of .56 was achieved (a moderate 
  correlation). </p>
<table width="25%" border="0">
  <tr class="heading"> 
    <td>Course Level</td>
    <td>N</td>
  </tr>
  <tr> 
    <td>Other</td>
    <td>2</td>
  </tr>
  <tr> 
    <td>Professional Develoment</td>
    <td>8</td>
  </tr>
  <tr> 
    <td>Graduate</td>
    <td>15</td>
  </tr>
  <tr> 
    <td>Post-Secondary</td>
    <td>25</td>
  </tr>
  <tr> 
    <td>Secondary</td>
    <td>2</td>
  </tr>
</table>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>Table 1: Education level of DE courses.</i> </p>
<p>These educators delivered courses through a variety of means with the Internet 
  being the chief mode of delivery (see Table 2). Eight educators used more than 
  one delivery mode. Even though there have been long-standing guidelines for 
  Internet accessibility such as the Web Accessibility Initiative (WAI), of the 
  33 respondents, 19 stated that they had not used any accommodation to make their 
  course accessible to learners with special needs (see Figure 1). The course 
  subject areas spanned a wide range of subjects with the majority being sciences, 
  humanities and education. </p>
<p>We asked educators what three things they believed were critical in fostering 
  course success. Of the 15 possible coding categories, five categories were most 
  commonly reported: Technology, Interaction, Tech Support, No Response and Course 
  Management with Interaction having the greatest count at 18 of 33 respondents. 
</p>
<table width="25%" border="1">
  <tr class="heading"> 
    <td>Course Level</td>
    <td>N</td>
  </tr>
  <tr> 
    <td>Other Modification</td>
    <td>4</td>
  </tr>
  <tr> 
    <td>None</td>
    <td>19</td>
  </tr>
  <tr> 
    <td>W3C</td>
    <td>8</td>
  </tr>
  <tr> 
    <td>ASL</td>
    <td>1</td>
  </tr>
  <tr> 
    <td>Describing Video</td>
    <td>1</td>
  </tr>
  <tr> 
    <td>Captioning</td>
    <td>2</td>
  </tr>
</table>
<p><i>Table 2: Number of respondents using accessibility modifications.</i> </p>
<img src="img/a_fig1.gif" width="211" height="125"> 
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>Figure 1: Count of delivery mode for distance courses.</i> </p>
<p>Educators were also asked what recommendations they would make to a new distance 
  educator. Possible categories of responses were: technology, leaning theory, 
  general teaching theory & methods, communication load, tech support, workload, 
  experience, no response, distance ed strategies, other, course management, career 
  implications and administrative support. Thirty-three percent (11/33) provided 
  recommendations in the communication category. When asked what pitfalls they 
  would warn new distance educators about, 31% of the respondents noted the increased 
  workload and demands on the instructor related to distance education. The next 
  two most frequently cited pitfalls were related to issues around administration 
  (17%) and career (13%) Table 3 outlines other response categories and ICC rating. 
</p>
<table border="0">
  <tr class="heading"> 
    <td>Response Category</td>
    <td>Count</td>
    <td>ICC</td>
  </tr>
  <tr> 
    <td>Technology &nbsp;</td>
    <td>15%&nbsp;</td>
    <td>26%&nbsp;</td>
  </tr>
  <tr> 
    <td>Leaning Theory &nbsp;</td>
    <td>13%&nbsp;</td>
    <td>14%&nbsp;</td>
  </tr>
  <tr> 
    <td>General Teaching Theory & Methods &nbsp;</td>
    <td>5%&nbsp;</td>
    <td>-9%&nbsp;</td>
  </tr>
  <tr> 
    <td>Communication Load &nbsp;</td>
    <td>3%&nbsp;</td>
    <td>29%&nbsp;</td>
  </tr>
  <tr> 
    <td> Tech Support &nbsp;</td>
    <td>2%&nbsp;</td>
    <td>-9%&nbsp;</td>
  </tr>
  <tr> 
    <td>Workload &nbsp;</td>
    <td>30%&nbsp;</td>
    <td>65%&nbsp;</td>
  </tr>
  <tr> 
    <td> Experience &nbsp;</td>
    <td>7%&nbsp;</td>
    <td>-9%&nbsp;</td>
  </tr>
  <tr> 
    <td>No Response &nbsp;</td>
    <td>3%&nbsp;</td>
    <td>-4%&nbsp;</td>
  </tr>
  <tr> 
    <td> Distance Ed Strategies &nbsp;</td>
    <td>32%&nbsp;</td>
    <td>29%&nbsp;</td>
  </tr>
  <tr> 
    <td> Other &nbsp;</td>
    <td>0%&nbsp;</td>
    <td>0%&nbsp;</td>
  </tr>
  <tr> 
    <td> Course Management &nbsp;</td>
    <td>2%&nbsp;</td>
    <td>-4%&nbsp;</td>
  </tr>
  <tr> 
    <td>Career Implications &nbsp;</td>
    <td>5%&nbsp;</td>
    <td>74%&nbsp;</td>
  </tr>
  <tr> 
    <td>Administrative Support &nbsp;</td>
    <td>11%&nbsp;</td>
    <td>0.81&nbsp;</td>
  </tr>
</table>
<p><i>Table 3: DE Pitfall Categories and Reliability Rating</i> </p>
<p><i>Discussion</i> <br />
  The results from this survey reveal important issues related to course delivery, 
  learner needs and instructor needs in the field of distance education. The most 
  common medium for course delivery reported by our respondents was the Internet 
  yet more than half of the respondents said that they had not made any accommodations 
  to make their courses accessible to individuals with special needs. The question 
  of why this number may be so low needs to be addressed. It is unlikely that 
  instructors and course developers are deliberately seeking to exclude some learners 
  from their content. It is more likely that course developers are not sure how 
  courses can be made accessible or are not able to acquire accessible content 
  for their courses. The Barrierfree project is timely in its efforts to enable 
  course developers to have access to tools and content that will make online 
  courses accessible to all learners. </p>
<p>Of particular interest to this project was the rating by respondents of “comfort 
  with technology” for the instructor and learner as a critical factor for success 
  . The result highlights the importance of user-friendly design for the learner 
  and instructor interfaces as key in fostering course success in this new medium. 
</p>
<p>The respondents already involved in distance education noted the great demand 
  and workload they experience as well as reduced legitimacy in terms of administrative 
  support and opportunity for career advancement. It is important that any tool 
  developed to make courses accessible does not add to the burden of work already 
  experienced by the distance educator, indeed, any new tool should seek to reduce 
  this burden. </p>
<p>Online education could be the mode of education that is most freeing and accessible 
  to learners. The possibility to reach learners anywhere and in a myriad of accessible 
  ways is a genuine promise of the medium yet educators in this medium are not 
  experiencing the same institution respect and opportunity as they have in non-distance 
  modes of education. The importance and potential universal reach of broadband 
  education must be commensurate with the recognition by education institutions 
  of the contribution of distance educators. This important medium for education 
  requires not only quality content but also quality instructors and all that 
  can be done to recruit and maintain these instructors must be done at the institution 
  level to make the goal of universal access to quality education a reality. </p>
<p><i>ASL Translation Formats</i><br />
  As part of the project, research into optimal ways to make content accessible 
  to ASL speaking learners, two different ASL versions of the Canadian Learning 
  Television’s Room for Five learning video were produced with the Canadian Hearing 
  Society and Marble Media Inc. The first version was acted ASL where the ASL 
  equivalent of the video is provided by actors in costume. The second version 
  was an ASL interpretation of the video material. The study focused on the ASL 
  presentation mode, video viewing options (video size, proximity and borders) 
  and comprehension. </p>
<p><i>Evaluation Process</i><br />
  Our goal was to study which ASL presentation options were optimal for learning 
  and learner engagement with the educational content. The research objectives 
  associated with this goal were thus: to determine what enhancements to ASL translation 
  are effective for viewers to examine the effects of different ASL presentation 
  formats on learning to inform design of courseware software Pre, post and comprehension 
  questionnaires were developed (see pp. 45, 48 & 47) to gather opinions and performance 
  of ASL speaking learners in order to gain an understanding of user preferences 
  for ASL videos and viewing options,. Think aloud protocol (TAP), a standard 
  usability evaluation method (UEM) was adapted for use with ASL speakers. </p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<p><i>Methods</i> <br />
  Seventeen participants were asked to complete a pre-study questionnaire containing 
  questions about the participant’s experience with online video, computers and 
  ASL translations of video material. A post-study questionnaire that focused 
  on the usability of the interface and viewing features was also completed by 
  each participant. The participant had the option to have any written material 
  translated into ASL and to respond in ASL. These methods are outlined below 
  and in more detail in Roberts & Fels (2002). </p>
<p> <i>Participant Training & Practice </i><br />
  Participants were trained on using the video controls and viewing preferences 
  of the interface. TAP was explained to and practiced by participants while watching 
  a practice video. At the close of the practice session participants selected 
  their viewing preferences for first video. </p>
<p>ASL viewing types There were two different styles of ASL translation for this 
  study: 1) standard translation and 2) acted translation. Standard translation 
  used a single translator wearing street clothing against a solid background. 
  A single video window was used to display the ASL translation. Acted ASL translation 
  used actors speaking ASL The actors were dressed in costume similar to the costumes 
  used in the original video but did not act out the parts other than in sign 
  language. Backgrounds and lighting were also used to reflect the mood of a particular 
  scene. However, sets were not used. The acted ASL was displayed using two video 
  windows so that different actors could appear simultaneously (similar to how 
  the actors appear in the original video). The ASL video windows were synchronized 
  and displayed with the original video. </p>
<p><b>Video controls and viewing preferences</b> </p>
<p>Video controls in the interface allowed the user to play, pause, move forward 
  or rewind the video (and the ASL translation video). Viewing preferences could 
  also be set by the user and included video and ASL translation window positions, 
  proximity of the windows, relative size of the windows and use of borders around 
  the windows. Participants could locate the ASL translation windows below, beside 
  or above the original video window, and they could make the ASL windows larger 
  or smaller than the original video display window. </p>
<p><i>Viewing of Video</i><br />
  Following training, individuals were asked to watch two 10-minute videos (acted 
  ASL and interpreted ASL). After the first video, participants completed a short 
  multiple-choice test for content comprehension. Next, participants were again 
  provided opportunity to set viewing preferences for the educational video. Once 
  the favoured settings had been selected, participants viewed the same educational 
  video segment but with the other ASL translation format from the first viewing. 
  For example, if the first video viewed used acted ASL then the second viewing 
  used standard ASL translation. The order of viewing was randomly assigned to 
  each participant. Participants were involved in the training and experiment 
  for approximately one hour. </p>
<p><i>Think aloud Protocol</i> <br />
  Participants were asked to sign their thoughts while manipulating the interface 
  and watching the video. After short periods of silence (about ten seconds) or 
  indications of thought such as facial expressions or head nodding, the investigator 
  would remind the participant to sign these thoughts. </p>
<p><a href="#top"><img src="../img/top.gif" width="14" height="13" align="right"></a></p>
<h4>Analysis</h4>
<p><i>Verbal Protocol Analysis</i><br />
  A protocol for assessing the transcriptions was developed based on the study 
  objectives. As shown in Table 6, eight categories were established with six 
  categories having positive or negative as subcategories. One category coded 
  direct comparisons between the two translation types and the last category was 
  a simple count (see 50 for categories and a sample comments). Due to technical 
  failures, only 13 participants have full data sets and only these full sets 
  are included in the analysis. Five of the participants viewed the ASL video 
  first. Also, only the analysis of the verbal protocols collected during the 
  two video viewing sessions is reported here. </p>
<p>Two operators were instructed on how to use the interface and the meaning of 
  operationally defined categories. The intraclass coefficient (ICC) was high 
  (ICC = .88, P<0.05) across categories. This level is sufficiently high to allow 
  the remaining analyses to be carried out by one individual. </p>
<p>Results Video and Translation Ratings Participants’ ranking of quality and 
  comprehensibility of the two translation types did not vary with treatment order. 
  Furthermore, chi square analysis showed that participants significantly liked 
  the educational video (content _2=10.71, characters _2=7.12, plot _2=7.88; p<.05 
  for each category) and the quality of the ASL interpretations (_2=10.71; p<0.05). 
</p>
<p>Comprehension test The results of the comprehension test were evenly split 
  between the two treatments such that of the 8 participants who scored at least 
  4 correct out of 7 questions (57%), 4 completed the test after watching the 
  acted interpretation and 4 after watching the standard ASL interpretation. </p>
<p><i>Preferences & Features </i><br>
  While online delivery of courses is now quite common, it is not common to provide 
  concurrent ASL video translation to videos with sound as an accommodation to 
  students who are deaf. Furthermore, flexibility over the way these videos are 
  viewed (preference settings for size, position, proximity and borders enabled) 
  is an additional and innovative feature of the interface in this study. We asked 
  participants if they would be willing to pay for these features and if the features 
  were worthy of the related rise in production costs. </p>
<p>As is shown in Figure 2, 14 of the 17 participants suggested that the acted 
  video was worthy of extra production costs and that having the flexibility to 
  control how the video is viewed as less desirable than having acted video (only 
  9 of the 17 participants rated viewing preferences as more worthy or very worthy). 
  However, when asked about willingness to pay these extra costs, the affirmative 
  trend, although still there, was less distinct with a more even distribution. 
</p>
<img src="img/a_fig2.gif" width="313" height="143" alt="figure 2"> 
<p><i>Figure 2: Worthiness of Added Production Costs. The added features are generally 
  seen as worthy of the associated rise in production cost</i>. </p>
<i>Preference Settings </i> 
<p>As might be expected, viewing preferences varied considerably from participant 
  to participant. One clearly popular setting was to have the ASL window large 
  with all but one participant stating that it was their preferred setting. Also, 
  12 of the respondents preferred to have the ASL window below the original video 
  window. Other choices such as borders and proximity showed no particular pattern 
  or preference. </p>
<i>Verbal Protocol Analysis</i> 
<p>Each of the 26 ten-minute video sessions yielded at least one coded comment 
  with the average number of comments per session being 8.4. Table 4 provides 
  a summary of the number of comments in each category. </p>
<table border="1">
  <tr class="heading"> 
    <td colspan="5">Acted</td>
    <td>Interpreted</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Quality of interpreter/actors presence and expression</td>
    <td colspan="2">+ve</td>
    <td>20</td>
    <td>10</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>4</td>
    <td>8</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Interpretation quality (speed, novel signs)</td>
    <td colspan="2">+ve</td>
    <td>8</td>
    <td>5</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>10</td>
    <td>20</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Ease of using video interface (video control buttons)</td>
    <td colspan="2">+ve</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Viewing preferences (position, border, size, proximity)</td>
    <td colspan="2">+ve</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>4</td>
    <td>0</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Technical issues with video (synchronicity, visibility)</td>
    <td colspan="2">+ve</td>
    <td><b>8</b></td>
    <td><b>0</b></td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>28</td>
    <td>23</td>
  </tr>
  <tr> 
    <td rowspan="2" colspan="2">Content of video </td>
    <td colspan="2">+ve</td>
    <td>1</td>
    <td>2</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>6</td>
    <td>6</td>
  </tr>
  <tr> 
    <td rowspan="5">Acted vs interpreted ASL content (comparison, busyness)</td>
    <td rowspan="3">Acted</td>
    <td colspan="2">+ve</td>
    <td>1</td>
    <td>8</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">-ve</td>
    <td rowspan="2">8</td>
    <td rowspan="2">3</td>
  </tr>
  <tr> </tr>
  <tr> 
    <td rowspan="2">Interpreted</td>
    <td colspan="2" height="2">+ve</td>
    <td height="2">12</td>
    <td height="2">1</td>
  </tr>
  <tr> 
    <td colspan="2">-ve</td>
    <td>15</td>
    <td>5</td>
  </tr>
  <tr> 
    <td colspan="4">Closed Captioning Requested</td>
    <td>0</td>
    <td>3</td>
  </tr>
  <tr class="heading"> 
    <td colspan="4">Total</td>
    <td>125</td>
    <td>94</td>
  </tr>
</table>
<p><i>Table 4: Count of coded comments for each category</i> </p>
<p>A moderate correlation between translation type and number of comments was 
  found [r(13) = .7] such that the acted interpretation generally garnered more 
  comments. Viewing order, however was not correlated with number of coded comments. 
  Furthermore, no association between viewing order or translation type and the 
  total number positive or negative coded comments was found thus participants 
  made positive or negative comments about the same number of times regardless 
  of the translation type or order in which the video was viewed. Table 5 summarizes 
  these findings. </p>
<table border="1">
  <tr class="heading"> 
    <td>Comment </td>
    <td>Order</td>
    <td>Acted</td>
    <td>Interpreted</td>
  </tr>
  <tr> 
    <td rowspan="2">positive</td>
    <td>First</td>
    <td>1.4</td>
    <td>1.5</td>
  </tr>
  <tr> 
    <td>Second</td>
    <td>8.0</td>
    <td>6.1</td>
  </tr>
  <tr> 
    <td rowspan="2">negative</td>
    <td>First</td>
    <td>5.4</td>
    <td>2.8</td>
  </tr>
  <tr> 
    <td>Second</td>
    <td>4.4</td>
    <td>3.8</td>
  </tr>
</table>
<p><i>Table 5: Mean number of comments/type for each ASL viewing.</i> </p>
<p>T-tests were used to determine whether video watching order and ASL interpretation 
  type affected the quantity of positive and negative comments. There were significantly 
  more positive comments regarding technical issues during the second session 
  (t(24)=-2.3, p<.05) as well as during the acted translation (t(24)=-2.3 p<.05). 
  All but one of these comments referred to the use of costumes by the interpreter 
  actors. </p>
<p>Order was also a significant factor in three of the four comparison categories 
  with most of the comments being made during the second video session. Table 
  6 and Table 7 illustrate these findings. </p>
<p>Order was also a significant factor in three of the four comparison categories 
  with most of the comments being made during the second video session. Table 
  6 and Table 7 illustrate these findings. </p>
<table border="1">
  <tr class="heading"> 
    <td>Category</td>
    <td>t results&nbsp;</td>
    <td>Sig. Level</td>
  </tr>
  <tr> 
    <td>+ve acted</td>
    <td>t(24)=-2.1</td>
    <td>.05</td>
  </tr>
  <tr> 
    <td>-ve acted</td>
    <td>t(24)=-1.1</td>
    <td>n.s.</td>
  </tr>
  <tr> 
    <td>+ve interpreted </td>
    <td>t(24)=-2.6</td>
    <td>.05</td>
  </tr>
  <tr> 
    <td>-ve interpreted </td>
    <td>t(24)=-2.1</td>
    <td>.05</td>
  </tr>
</table>
<p><i>Table 6: T-test results for differences in means grouped by video order</i> 
</p>
<table border="1">
  <tr class="heading"> 
    <td>&nbsp;</td>
    <td>Order</td>
    <td>N</td>
    <td>Mean</td>
    <td>SD</td>
  </tr>
  <tr> 
    <td rowspan="2"> +ve technical issues </td>
    <td>1</td>
    <td>13</td>
    <td>.00</td>
    <td>.00</td>
  </tr>
  <tr> 
    <td>2</td>
    <td>13</td>
    <td>.62</td>
    <td>.96</td>
  </tr>
  <tr> 
    <td rowspan="2">+ve interpreted </td>
    <td>1</td>
    <td>13</td>
    <td>.00</td>
    <td>.00</td>
  </tr>
  <tr> 
    <td>2</td>
    <td>13</td>
    <td>.69</td>
    <td>.95</td>
  </tr>
  <tr> 
    <td rowspan="2">-ve interpreted</td>
    <td>1</td>
    <td>13</td>
    <td>.08</td>
    <td>.28</td>
  </tr>
  <tr> 
    <td>2</td>
    <td>13</td>
    <td>.77</td>
    <td>1.17</td>
  </tr>
  <tr> 
    <td rowspan="2">+ve acted</td>
    <td>1</td>
    <td>13</td>
    <td>.00</td>
    <td>.00</td>
  </tr>
  <tr> 
    <td>2</td>
    <td>13</td>
    <td>1.00</td>
    <td>1.68</td>
  </tr>
</table>
<p><i>Table 7: Mean and standard deviation for significant results in number of 
  comments by order (n=13).</i> </p>
<p>Most of the negative acted scores stemmed from comments about the difficulty 
  involved in watching two interpreters at the same time. When grouped by viewing 
  order, a t-test of –ve interpretation quality did approach significance (t(24)=1.9, 
  p<.07). </p>
<p><i>Discussion</i></p>
<p>Participants were not at a disadvantage for the comprehension test due to translation 
  order or video content issues. The failure rate on the comprehension test was 
  high but may relate to the task demands placed on the participants. In this 
  case, participants were conscious of reporting usability issues to the investigator 
  while at the same time working with and learning from the novel interface and 
  video. A comparison of test results to participants who are hearing and who 
  are asked to carry out the same procedures with the original video could provide 
  additional insight into the difficulties of reporting usability issues while 
  at the same time trying to learn about content. Also, since the multiple choice 
  test was presented in written English (although ASL interpretation of the questions 
  was always available) it may have been useful to include the closed caption 
  English track of the video script. In this way, participants would have opportunity 
  to see the information in the same language in which the test was presented. 
  Comprehension results would likely increase if the educational component and 
  test were part of an actual course in which the participants would have a vested 
  interest in studying and reviewing the material. The cost data shows a trend 
  towards willingness of participants to pay for either a standard or acted interpretation 
  of the video as well as for provision of viewing preferences control. This preference 
  viewing information is particularly valuable in cases where a product’s viewing 
  preferences are static. Developers of such an interface would be able to base 
  decisions on known preference data and have at least a greater chance of meeting 
  the preferences of a greater proportion of the deaf population. More research 
  on viewing preferences and their potential effect on the learning process should 
  be carried out so that accommodation standards may be determined for the courseware 
  industry. </p>
<p>The verbal protocols show that participants were able to think aloud while 
  attending to an educational video. The resulting analysis indicates that participants 
  were able to detect a variety of issues within the videos and to report these 
  issues consistently regardless of presentation order. There were no coded comments 
  regarding the ease of use of the video interface which could be considered disappointing. 
  However, this result may be accounted for in three ways. First, the video controls 
  were standard control buttons associated with a tape playing device and would 
  be very familiar to most individuals. Second, the participants were more interested 
  in the novelty of watching ASL video and were more apt to comment on related 
  video issues. Finally, the participants tended to use the controls before viewing 
  the videos, however, only protocols obtained during the video sessions are reported 
  here. </p>
<p>More negative comments about interpretation quality were made in the first 
  video session than the second video session regardless of ASL presentation. 
  Common user comments in this category related to the speed of the interpreter. 
  This issue may be mitigated by opportunity to replay the video and it is possible 
  that the repetition of the ASL in the second video session accounts for the 
  reduced number of negative comments regarding interpretation quality during 
  that session. </p>
<p>It is noteworthy that closed captioning was only requested three times. The 
  requests were made by two of the thirteen participants and each time during 
  the first video session which in both cases was a viewing of the interpreted 
  video. Since closed captions are the most common form of accommodation to video 
  material for users who are deaf, we may have expected this category to have 
  a higher count. The lower count may indicate that learners who use gestural 
  language for communication are more comfortable viewing educational material 
  in this format. It is also suggestive of the fact that generally ASL speakers 
  have lower literacy levels in a second language such as English. Certainly, 
  the result suggests that learners did not feel at a loss without video captions. 
  This finding along with findings from the survey data suggest that ASL video 
  may be a viable and possibly preferred alternative to captioned hearing videos. 
  The kind of access that learners have to the Internet has improved significantly 
  and online educational content may realistically go beyond traditional text-based 
  formats. Indeed, as this research attempts to show, alternative ways of presenting 
  educational material on the Internet are deserving of further investigation. 
</p>
<p><i>Player Evaluation Evaluation Process</i> </p>
<p>Our goal was to evaluate the learnability and usability of the player tool. 
  The player tool is further described in section 2. We investigated player usability 
  as a function of ease of learning the interfaced and level of intuitiveness 
  or use for learners. Three stages of evaluation of the player were carried out: 
  heuristic evaluation, beta testing and usability testing. At each stage, the 
  course content was a segment of a physics video from the World in Motion series 
  produced by the CLT as well as content such as linked definitions, described 
  video and captions added by the research team. </p>
<p>Methods Heuristic Evaluation The formative evaluation of the player involved 
  assessment of models of the player and the player itself using heuristics developed 
  by Jakob Nielson (1994). This methodology is based on evaluation of the design 
  by expert designers using prescribed usability heuristics, with specific focus 
  on disability issues for each heuristic. These heuristics are outlined on page 
  42 of this report. </p>
<p><i>Beta Testing </i> </p>
<p>Further formative evaluation of the player involved beta-testing the player 
  by usability researchers and then by focus groups. The researchers analysed 
  the player in the role of learners. This analysis included usability heuristics, 
  user expectations, accessibility and intuitiveness. From this data, issue and 
  bug reports were created and given to the player development team. Once initial 
  issues and bugs had been reviewed and mitigated by the development team, target 
  user representatives were recruited for a more formal study. Participants worked 
  with the player individually in a standardized test format that included pre 
  and post surveys, a comprehension test and think aloud protocol. Participants 
  included individuals who are blind or have low vision, hard of hearing, learning 
  disabled, and no diagnosis. </p>
<p><i>Usability Testing</i> </p>
<p>Usability testing took the same format as the beta and focus group testing 
  but was carried out after issues raised in the earlier investigation had been 
  reported to and mitigated by the development team. User groups were as follows: 
  blind (2), low vision (2), hard of hearing (6), learning disabled (3) and no 
  diagnosis (4). In all, 17 individuals participated in the usability testing 
  phase. </p>
<h4 class="blu">Results and Discussion</h4>
<p>The player underwent several stages of evaluation. The initial stages were 
  iterative and the resulting issue reports informed the ongoing development of 
  the player tool. Testing with focus-groups enabled the investigators to identify 
  further issues of access or player use that are specifically related to mode 
  of access or disability. After further development, usability testing with specific 
  user groups was carried out. </p>
<p>All of the usability test participants reported that they were daily computer 
  users. Furthermore 12 of the 17 participants reported that they were somewhat 
  (7) or very familiar (5) with their computer video player. Only five of the 
  participants had taken a web-based course before. All of the participants were 
  given three content questions (see p. 51) to answer that would force the participant 
  to use different player features in order to find the answer. The results showed 
  that all of the participants were able to try hyperlinks to additional material. 
  However, linking for the blind participants was very difficult and brought forward 
  some issues related to using the player with screen readers (e.g. inability 
  to have links read out, difficulty accessing some windows). These were communicated 
  to the development team. Most of the participants struggled with a formula content 
  question although 15 of the participants did navigate correctly to the calculations 
  content page that contained the link to the correct answer. Once again participants 
  who were blind were not able to navigate to the answer. These findings show 
  that participants (excluding those using screen readers) were able to successfully 
  navigate through the course content and any difficulty finding the correct answer 
  was more likely due to the question rather than user navigation abilities.</p>
<p>The content questions of the session helped us to understand how participants 
  used the player features in their learning as well as to identify further uses 
  for the video accommodations. For example, all of the participants used the 
  captions to search for answers. A variety of methods were employed from stepping 
  through the captions using the video controls, or by reading and/or searching 
  the full text of the captions. Several participants who were not hard of hearing 
  and therefore not reliant on captions reported that they liked having captions 
  with the video. This finding demonstrates the widespread benefit of inclusive 
  design where an accommodation such as captions for one user group has benefits 
  for other groups as well. Transcriptions of the verbal protocol from each session 
  were made and used to create issue reports for the development team. These reports 
  include user likes, dislikes and difficulties with the player. Software is typically 
  used in ways that is not foreseen by the developers and this protocol helps 
  to inform the team of the rationale behind user decisions as well as expose 
  difficulties experienced by the user (see pp. 52 & 53 for examples). </p>
<p><i>Authoring Tool Evaluation Evaluation Process</i> </p>
<p>Our goal was to evaluate the usability of the authoring tool as described in 
  section 2. Three stages of evaluation of the authoring tool were planned: heuristic 
  evaluation, beta testing and usability testing. Unfortunately, time constraints 
  restricted full usability testing of the authoring tool. The identified test 
  group was educators who already utilize the internet for delivery of course 
  material. A number of this group were unable to set aside the required time 
  to review and try the authoring tool at the beginning of the school year. However, 
  a heuristic evaluation and beta testing was carried out. </p>
<p><i>Methods Heuristic Evaluation</i> </p>
<p>The evaluation of the authoring tool also followed the usability heuristics 
  developed by Jakob Nielson (1994). These heuristics are outlined on page 42 
  of this report. Beta Testing Further evaluation of the authoring tool involved 
  beta-testing of the player by usability experts. Researchers used and analysed 
  the authoring tool in the role of educators or course developers. The analysis 
  included usability heuristics, user expectations, and intuitiveness. From this 
  data, an issue and bug report was created and given to the development team. 
</p>
<p><i>Results and Discussion</i> </p>
<p>The evaluation of the authoring tool identified 12 issues (see p. 56). Once 
  an issue was identified a suggestion for addressing the issue was made and reported 
  to the development team. Although full summative user-testing could not be carried 
  out within the project time-frame, initial evaluation shows that the authoring 
  tool is not complicated to use and compilation of new and existing media tracks 
  is intuitive. There were some issues around the use of technical language that 
  confuse novice users. Changes to the current structure of the meta-data input 
  were recommended. Meta-data is a particularly important component for the sharing 
  of learning objects and requires precise language and categories. A simple but 
  structured means to draw the relevant information from learning object creators 
  that will then automatically populate the meta-data fields was recommended. 
</p>
<p><i>Impact on project </i> </p>
<p>The results of all of the evaluations provided a significant contribution to 
  the project. The formative evaluations for the player and the authoring tool 
  provided valuable information during the development cycle when it was simpler 
  and less expensive to make changes. Issues discovered during the evaluation 
  process informed and helped developers to make design improvements and decisions 
  that were best suited to users. It is often difficult for developers to predict 
  user reaction to and usability of designs particularly when target user populations 
  are so diverse. As a result of the evaluations, the player and authoring tools 
  can be successfully used by people who are deaf, hard of hearing, vision impaired, 
  learning disabled and others. </p>
<p><i>Impact on community </i></p>
<p>The evaluation carried out to explore alternative presentation and customized 
  controls for American Sign Language translations of video material did not inform 
  the design of the player or authoring tools but it did provide important information 
  about customized controls and ASL preferences for video. </p>
<p>Shared with the partners in the Barrier-free project, The Canadian Hearing 
  Society’s mission is to provide services that enhance the independence of deaf, 
  deafened and hard of hearing people and that encourage prevention of hearing 
  loss. The implications of and results from the ASL portion of the Barrier-Free 
  project, will greatly enhance the independence of the Deaf. </p>
<p>We were interested in finding ways that could better enhance the comprehension 
  of online material for deaf individuals. Deaf individuals have a right to receive 
  information in their native language – sign language. It is also their right 
  to access video material that has the same richness and entertainment value 
  as with an oral video. Many people assume that written material including closed 
  captions is sufficient for the Deaf. In majority of cases this is not so and 
  therefore we needed to explore options for access to video material. </p>
<p>The experimental results show that the Deaf are interested in new variations 
  of video formats (rather than the conventional closed captioning). Having these 
  formats available online will allow deaf individuals to have improved educational 
  opportunities such as online distance courses. It will also allow content developers 
  to produce effective ASL translations of their video material. It also demonstrated 
  that customizable formatting for ASL display spaces is desirable and worthwhile 
  including in player or presentation systems, although a complete cost-benefit 
  analysis remains to be carried out to determine the most cost effective. </p>
<p>The Internet has become an essential communication tool for the Deaf. By developing 
  and delivering web-based material in sign language the potential is immeasurable. 
  Educational courses online could be translated into any sign language (over 
  100 around the world). Important government forms (often difficult to comprehend) 
  could be explained in sign language with a glossary of difficult terms explained 
  in sign language as well. Deaf individuals with lower levels of literacy often 
  rely on interpreters, family, friends, volunteers and CHS counsellors to explain 
  how to fill out forms such as the annual income tax forms. With explanations 
  in sign language, these deaf individuals would rely less on others and increase 
  their independence. </p>
<p>The impact on other communities of people with disabilities is also significant 
  with the development and deployment of the player and authoring tools. Not only 
  is the Internet important for people who are Deaf but also it is important to 
  a wide range of communities who find access to traditional or conventional learning 
  systems difficult or cumbersome. The player and authoring tool have been design 
  and evaluated with various populations of users and found to be accessible and 
  usable. </p>
<p>Allowing content designers and creators to easily produce accessible on-line 
  learning material for many different types of learners increases the potential 
  benefit to all users as evidenced by the use of the closed captions in our experiments. 
  It also means that on-line content can meet legislative requirements and standards 
  for accessibility. </p>
<h4>References</h4>
<p>Baumgartner, P. & Payre, S.(1998). Learning with the internet. A typology of 
  applications. Paper presented at Ed-Media/Ed-Telecom 98 World Conference on 
  educational multimedia and hypermedia and world conference on telecommunications. 
  Proceedings (10th). Freiburg, Germany, June 20-25.</p>
<p>Belanger, France and Jordan, Dianne H. (2000). Evaluation and Implementation 
  of Distance Learning: Technologies, Tools, and Techniques. Idea Group Publishing:Hershey, 
  PA Dooley, K., Edmundson, C., & Hobaugh, C. (1997). Instructional Design: A 
  Critical Ingredient in the Distance Education Soup. (ERIC Document Reproduction 
  Service No. ED 415 935). </p>
<p>Grubbs, L, & Lockey, Mick, (2000). Get smart: the pluses and minuses of e-learning. 
  PC World Communications, Inc. 18, 11, 116-123. </p>
<p>Hiltz, S.R. & Turoff, M. (1985). Structuring computer-mediated communication 
  systems to avoid information overload, Communications of the ACM. v.28(7). 680-689. 
</p>
<p>Nielsen, J. (1994). Heuristic evaluation. In Nielsen, J., and Mack, R.L. (Eds.), 
  Usability Inspection Methods, John Wiley & Sons: New York, NY. </p>
<p>Olsen, J.S., Olsen, G.M. & Meader, D.K., (1995). What Mix of Video and Audio 
  is Useful for Small Groups Doing Remote Real-Time Design Work? CHI’95. Denver. 
  pp. 362-368. </p>
<p>Roberts V. & Fels, D. Methods for inclusion: employing think aloud protocol 
  with individuals who are deaf. In Miesenberger, K., Claus, J. & Zagler, W. (Eds.), 
  Computers Helping People With Special Needs: 8th Annual Conference Proceedings/ICCHP 
  2002: Springer: New York. (2002). pp.284-291, 2002. </p>
<p>Schoech, D. (2000). Teaching over the internet: results of one doctoral course. 
  Research in Social Work Practice, 10,4, 467-487. </p>
<p>Schutte, J.G. (2001). Virtual teaching in higher education: the new intellectual 
  superhighway or just another traffic jam? Paper presented at CSUN (April 200). 
</p>
<p>Sweet, R. (2000). Distance education for adult learners: developments in Canadian 
  post-secondary system. Canadian Journal for the Study of Adult Education, 14(1), 
  1-26. </p>
<p>Thomson, J.S., Stringer, S.B. (1998). Evaluation for distance learning: feedback 
  from students and faculty. In: Distance Learning ’98. Proceedings of the Annual 
  Conference on Distance Teaching and Learning (14th, Madison, WI). 401-406. </p>
<p>Wallace, E. & Smythe D. (1999). Distance Education in Ontario’s Secondary Schools: 
  A Research Study. Submitted to the Independent Learning centre, Ontario Ministry 
  of Education and Training. </p>
<p>Zuniga, R.E. & Pease, P. (1998). Evaluating the virtual institution: the flashlight 
  project evaluation of international university. Paper presented at Annual Forum 
  of the Association for Institutional Research (38th Minneapolis, MN) </p>
<h4 class="blu">Appendices </h4>
<ul>
  <li>Ten Usability Heuristics </li>
  <li><a href="#dist_ed">Distance Education Expert Survey</a> </li>
  <li><a href="#pre_study">Pre-Study Questionnaire</a> </li>
  <li><a href="#comp">Comprehension Test</a> </li>
  <li><a href="#post_study">Post-Study Questionnaire</a> </li>
  <li><a href="#physics_?">Physics Content Questions</a> </li>
  <li><a href="#deaf_eval">Player Evaluation : Hard of Hearing, Caption Users</a> </li>
  <li><a href="#LD_notes">Player Group Two LD Session Notes</a> </li>
  <li><a href="#au_eval">Authoring Tool Evaluation</a> </li>
</ul>
<h4>Ten Usability Heuristics</h4>
<ol>
  <li><b>Visibility of system status:</b> The system should always keep users 
    informed about what is going on, through appropriate feedback within reasonable 
    time. </li>
  <li><b>Match between system and the real world:</b> The system should speak 
    the users' language, with words, phrases and concepts familiar to the user, 
    rather than system-oriented terms. Follow real-world conventions, making information 
    appear in a natural and logical order.</li>
  <li> <b>User control and freedom:</b> Users often choose system functions by 
    mistake and will need a clearly marked "emergency exit" to leave the unwanted 
    state without having to go through an extended dialogue. Support undo and 
    redo. </li>
  <li><b>Consistency and standards:</b> Users should not have to wonder whether 
    different words, situations, or actions mean the same thing. Follow platform 
    conventions.</li>
  <li><b>Error prevention:</b> Even better than good error messages is a careful 
    design which prevents a problem from occurring in the first place.</li>
  <li><b>Recognition rather than recall:</b> Make objects, actions, and options 
    visible. The user should not have to remember information from one part of 
    the dialogue to another. Instructions for use of the system should be visible 
    or easily retrievable whenever appropriate. </li>
  <li><b>Flexibility and efficiency of use:</b> Accelerators -- unseen by the 
    novice user -- may often speed up the interaction for the expert user such 
    that the system can cater to both inexperienced and experienced users. Allow 
    users to tailor frequent actions.</li>
  <li><b>Aesthetic and minimalist design:</b> Dialogues should not contain information 
    which is irrelevant or rarely needed. Every extra unit of information in a 
    dialogue competes with the relevant units of information and diminishes their 
    relative visibility. </li>
  <li><b>Help users recognize, diagnose, and recover from errors:</b> Error messages 
    should be expressed in plain language (no codes), precisely indicate the problem, 
    and constructively suggest a solution. </li>
  <li><b>Help and documentation:</b> Even though it is better if the system can 
    be used without documentation, it may be necessary to provide help and documentation. 
    Any such information should be easy to search, focused on the user's task, 
    list concrete steps to be carried out, and not be too large. (Nielsen, 1994) 
  </li>
</ol>
<a name="dist_ed"></a><h4>Distance Education Expert Survey</h4>
<p>We are compiling best practices for online distance education and ask that 
  you provide us with some of your expertise in this area by completing this short 
  survey. All responses will be kept strictly confidential. Thank you in advance 
  for your support and assistance.</p>
<p>Please provide some background information: </p>
<ol>
  <li>What education level do you teach?</li>

<ul>
  <li>secondary</li>
  <li>post-secondary</li>
  <li>graduate</li>
  <li>prof. development</li>
  <li>other ____________________________</li>
  
</ul>
<li>How many distance education courses/workshops have you developed?</li>
<li>How many years have you taught distance education courses/workshops?</li>
<li>How many online courses/workshops have you taught?</li>
<p>Please tell us about your courses:</p>
<li>What subject areas do you teach by distance education?</li>
<li>Through which of the following media do you provide distance education (choose all that apply)</li>
<ul>
  <li>video tape</li>
  <li>audio tape</li>
  <li>television</li>
  <li>print</li>
  <li>other ____________________________</li>
  </ul>

<li>Please check the modifications you have made to your courses/workshops to meet the needs of participants with special needs:</li>
<ul>
  <li>video captioning</li>
  <li>described video</li>
  <li>ASL translation</li>
  <li>W3C web criteria</li>
<li>none</li>
  <li>other ____________________________</li>
  </ul>
  <li>What three recommendations would you give to an instructor new to the distance 
    education methods?</li>
<li>What pitfalls would you warn an instructor new to the distance education method to watch out for?</li>
<li>What course elements do you believe are critical in fostering learner success in your distance ed. courses?</li>
  <li>Please provide any references that you believe are a must-read for distance 
    educators.</li>
<li>May we contact you to discuss your distance education practices further? If so please provide contact information:</li>
<div>
Name:&nbsp;____________________________<br />
Phone:&nbsp;____________________________<br />
Email:&nbsp;____________________________<br />
</div>

</ol>

 
<a name="pre_study"></a><h4>Pre-Study Questionnaire </h4>
<p>Participant #:&nbsp;____________________________ </p>
<ol>
<li> What is the highest level of education you have achieved?</li>
<ol type="A">
<li>some high school</li> <li>high school</li> 
<li>some college/university</li> 
<li>college/university</li>
</ol>
 
<li>How often do you use a computer?</li> 
<ol type="A">
<li>daily </li> 
<li>weekly</li> 
<li>monthly</li> 
<li>never</li>
</ol>
<li>Have you watched video material on a computer before? </li> 
<ol type="A">
<li>yes </li> 
<li>no</li> 
</ol>
<li>How often do you watch video material on a computer?</li> 
<ol type="A">
<li>daily </li> 
<li>weekly</li> 
<li>monthly</li> 
<li>never</li>
</ol>
<li>How familiar are you with the video player on your computer?</li>

<ol type="A">
<li>Not at all familiar</li> 
<li>Somewhat familiar</li> 
<li>Very familiar</li> 
</ol>

<li>Have you taken a workshop on the Internet before?</li> 
<ol type="A">
<li>yes </li> 
<li>no</li> 
</ol>

<li>How many Internet-based workshops have you participated in?</li> 
<li>What did you like about the Internet-based workshop?</li> 
<li>What did you dislike about the Internet-based workshop?</li> 

<li>Have you watched ASL video along with oral video before?</li> 
<ol type="A">
<li>yes </li> 
<li>no</li> 
</ol>
<li>How often do you watch ASL video?</li> 
<li>What do you like about ASL video?</li> 
<li>What do you dislike about ASL video?</li> 
<li>What is your usual approach to a video component?</li> 
</ol>

<a name="post_study"></a><h4>Post-Study Questionnaire </h4>
<p>Participant #:&nbsp;____________________________ </p>

<ol>
  <li>On a scale of 1-5 (1=very poor & 5=very good) please rate the following:</li>
  <table border="1">
    <tr class="heading"> 
      <td>&nbsp;</td>
      <td>Standard ASL Video</td>
      <td>Acted ASL Video</td>
    </tr>
    <tr> 
      <td>Comprehensibility of content </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Visual appeal of ASL </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Component Ability to engage with material </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Difficulty/Ease attending to the ASL Actor and video simultaneously 
      </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Clarity of ASL image </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Understanding of ASL Actor </td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </table>
  <li>Check your likes and dislikes (and neutral) of the following components:</li>
  <table border="1">
    <tr class="heading"> 
      <td> </td>
      <td>Dislike&nbsp;</td>
      <td>Like&nbsp;</td>
      <td>Did not notice&nbsp;</td>
    </tr>
    <tr> 
      <td>Subject matter&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Characters&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Plot&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Use of Costumes by ASL actors&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td>Borders around the videos&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr> 
      <td> Quality of ASL “enunciation”&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </table>
  <li>Would you pay to have this style of ASL added to your choice of video content? 
    Why/Why not?&nbsp;</li>
  <p> Standard ASL _____________________________ <br />
    Acted ASL _____________________________ <br />
    Control over ASL presentation (i.e. size, position)_____________________________ 
  </p>
  <li>Suggestions?</li>
  <p>&nbsp;</p>
  <li>Providing ASL in these formats would add extra costs to production. For 
    each format, rate the worthiness of these extra costs (where 1 = not at all 
    worthy & 5 = very worthy).</li>
  <p>Standard ASL&nbsp;&nbsp;&nbsp; <br />
    1&nbsp; 2&nbsp; 3&nbsp; 4&nbsp; 5 </p>
  <p>User-determined settings (i.e. position)&nbsp;&nbsp;&nbsp; <br />
    1&nbsp; 2&nbsp; 3&nbsp; 4&nbsp; 5&nbsp; </p>
  <p>Acted ASL&nbsp;&nbsp;&nbsp; <br />
    1&nbsp; 2&nbsp; 3&nbsp; 4&nbsp; 5&nbsp; </p>
  <li>Would you pay to have the following formats added to your choice of video?</li>
  <p>Standard ASL <br />
    Yes&nbsp;&nbsp; No </p>
  <p>User-determined settings <br />
    Yes&nbsp;&nbsp; No</p>
  <p>Acted ASL <br />
    Yes&nbsp;&nbsp; No </p>
  <li>What were your ASL box preferences (please check)? </li>
  <table border="1">
    <tr>
      <td>ASL Video Above Main Video</td>
      <td>OR</td>
      <td>ASL Video Below Main Video</td>
    </tr>
    <tr>
      <td>ASL Video Near Main Video;</td>
      <td>OR</td>
      <td>ASL Video Apart from Main Video</td>
    </tr>
    <tr>
      <td>ASL Video Smaller than Main Video</td>
      <td>OR</td>
      <td>ASL Video Larger than Main Video</td>
    </tr>
    <tr>
      <td>ASL Video with Border</td>
      <td>OR</td>
      <td>ASL Video without Border</td>
    </tr>
  </table>
  <li>Did you prefer to have a frame or no frame around the video? Why? 
</li>
  <li>Which video option did you prefer? (Large ASL Video, Small ASL Video) Why?</li>
  <li>Did you find the video interface easy to use? What problems did you experience with it? How might we improve it?</li>
 
</ol>









<table border="1">
  <tr class="heading"> 
    <td colspan="2">Category</td>
    <td colspan="2">Sample Comment</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Quality of interpreter/actors presence and expression</td>
    <td>&nbsp;</td>
    <td>Good facial expression.</td>
  </tr>
  <tr> 
    <td height="18">&nbsp;</td>
    <td height="18">The character looks mad but the interpreter is not showing 
      it.</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Interpretation quality (speed, novel signs)</td>
    <td>&nbsp;</td>
    <td>The interpreter keeps up well.</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>That is the wrong sign.</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Ease of using video interface (video control buttons)</td>
    <td>&nbsp;</td>
    <td>The reverse is useful.</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>How do I stop this thing?</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Viewing preferences (position, border, size, proximity)</td>
    <td>&nbsp;</td>
    <td>I like being able to move the ASL window.</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>There are too many choices.</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Technical issues with video (synchronicity, visibility)</td>
    <td>&nbsp;</td>
    <td>Good lighting.</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>The interpretation is not in synch with the video.</td>
  </tr>
  <tr> 
    <td colspan="2" rowspan="2">Content of video </td>
    <td>&nbsp;</td>
    <td>It makes sense.</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>Boring.</td>
  </tr>
  <tr> 
    <td rowspan="3">Acted vs interpreted ASL content (comparison, busyness)</td>
    <td rowspan="2">Acted</td>
    <td rowspan="3">&nbsp;</td>
    <td rowspan="3">&nbsp;</td>
  </tr>
  <tr> </tr>
  <tr> 
    <td>Interpreted</td>
  </tr>
  <tr> 
    <td colspan="2">Closed Captioning Requested</td>
    <td>&nbsp;</td>
    <td>You should have captions too.</td>
  </tr>
</table>
<p>&nbsp;</p>
<a name="physics_?"></a><h4>Physics Content Questions</h4>
<ol>
<li>
What is an Air Table? Draw one.</li>

<li>
Define Scalar and Vector?</li>

<li>
What is the equation for gravitational potential energy?</li>

</ol>

<a name="deaf_eval"></a><h4>Player Evaluation : Hard of Hearing, Caption Users</h4>

<b>Learning</b> <p><i>Captions and Annotations</i></p>

<p>All of the participants utilized extra features to answer the test questions. 
  Although the questions were designed to force participants to use the extra 
  features, it is significant that all of the participants regardless of their 
  comfort level with the interface did try hyperlinks in the captions to access 
  further information. Furthermore, two of the subjects examined the full text 
  captions and attempted to utilize a search function to find information within 
  the text. One subject was unsuccessful in employing her search because she had 
  her cursor in the wrong frame but definitely had a good concept of how to find 
  the information she required. All of the participants utilized the annotations, 
  however, all were told that there was information in the annotations that was 
  not available elsewhere in the captions or video. Even still, two of the participants 
  had to be directed to open annotations in order to view the additional information 
  (and find the answer to one of the questions).</p>
<p> Three of the five participants stated that it was difficult to attend to captions 
  and annotations at the same time. One participant found it impossible. While 
  participants may learn strategies for viewing captions and annotations such 
  as watching the video more than once or stepping back or forward through segments, 
  our participants seemed to prefer attempting to attend to both captions and 
  annotations. In this mode, however, 3 of the participants reported that things 
  moved too quickly. </p>
<p>Two of the participants verbalized that they liked the captions and one noted 
  that it was great to have the flexibility of positioning.</p>

<p><i>Hyperlink lists</i></p>
<p>All of the participants had to be reminded that the hyperlink list existed.  The need for reminder may have been compounded by the fact that the “show hyperlinks list” function on the general tab of the preferences dialogue was not working in the player version used for the evaluation and participants were more inclined to use this dialogue than the working settings menu.  Furthermore, only ten minutes of video were viewed by participants and while a hyperlink was displayed in the captions and annotations six times in that ten minutes, only two different links were shown.  For this reason, participants were less likely to need a listing of the hyperlinks to help their memory of the links or assist in navigating to the links. </p>

<p><i>User Errors/Bugs</i> </p>
<p>The three most common user errors were:</p>

<ol> 
<li>keying errors such as double-clicking on link lists and the TOC instead of right or ctrl clicks, </li>
<li> placing annotations and captions in the same location 
  and </li>
<li> black text on black backgrounds.</li>
</ol>

<p>The most common bug seemed to be related to the default settings whereby leaving the position of captions and annotations set to default made changes to font size and text type not take. Furthermore, the preview window would show the incorrect text position (compared to where the text was actually showing). </p>

<a name="LD_notes"></a><p><i>Player Group Two LD Session Notes</i> </p>
<table border="1">
  <tr class="heading"> 
    <td>&nbsp;</td>
    <td>Participant</td>
    <td>Comment</td>
  </tr>
  <tr> 
    <td>Learning</td>
    <td>401</td>
    <td>Used TOC and step forward to find test answers </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>401</td>
    <td>Confessed that artificial setting made him less inclined to explore the 
      wordy link list </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>401</td>
    <td>Doesn’t feel player will help with learning </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User wants text book model with full index/search function and glossary 
      in order to assist with exploration of material and learning </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User does not watch whole video </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Finds that stepping forward through captions is useful way to learn content 
      without listening/watching video </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Utilizes full text to find answers to test </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Attempts to find answers in TOC and full text caption rather than watch 
      whole video</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr> 
    <td>Captions & Annotations</td>
    <td>401</td>
    <td>Useful to help keep participant interested and focused in the video material 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>401, 300</td>
    <td>Participant finds tracking annotations, captions and video all at once 
      difficult </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Selection of caption type before turning on caption is backwards </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Full caption text does not make sense </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User able to change preferences comfortably but is not able to change 
      background colour due to black on black text and placement of text labels 
      as well as label colour </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>Participant utilizes captions and full text to find answers to test </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>User comfortable with changing font sizes </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Way captions are displayed is annoying. Doesn’t fit—larger than video 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Takes a bit of time before participant realizes that back button has to 
      be pressed repeatedly </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Participant fails to notice annotations first time through video </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Participant suggests ding to notify annotations </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Annotations are obscuring top of video (can’t see all of equation)</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr> 
    <td>Hyperlinks</td>
    <td>401</td>
    <td>Likes difference in link appearance as well as additional material </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>“narrative text” not understood </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Doesn’t look like a hyperlink list </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Why not put all of the same info on the same page instead of multiple 
      sub-links? </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>When open the hyperlink list is called the master link list </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Links embedded in captions or annotations are not accessible to users 
      who do not enable these features </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User not always clear on what is a hyperlink </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User uses links to find test answers </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>Link repetition in master link list is confusing to participant and causes 
      extra work to make sure links point to same information </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>Counter information with links is useless to participant since video does 
      not have counter </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>Blue of hyperlinks is difficult for participant to see </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>500</td>
    <td>User does not like right click</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Ding is scary—softer chime recommended</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr> 
    <td>Video Controls</td>
    <td>401</td>
    <td>Likes ability to skip parts he doesn’t want to watch </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Slider only indication of jumping through video—hard to tell that navigation 
      via TOC has had effect </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Forced type selection before enable seems backwards for any of the options 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Inconsistent language between general tap and onscreen settings </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>blocks in General Tab preview window are meaningless </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Participant does not realize that step forward is not continuous </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>Step buttons too slow for user </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User finds captions helpful despite not expecting to use them </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>Back button too slow—ends up using scrub bar </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>Participant has difficulty finding marker on scrub bar to take video back 
      to the beginning. </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>500</td>
    <td>Could make slider bigger for LVs (use java swing control instead of Quicktime) 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>500</td>
    <td>Have video counter or remove references to counter </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Need reset button to move video to beginning </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Slider used to move video to beginning </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>What is point of counter references when no counter</td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr> 
    <td>User Error/bugs/Issues</td>
    <td>401</td>
    <td>Calculations page noticeably confusing for participant </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Captions are showing at the bottom of the screen but the preview window 
      shows them at the top </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>401</td>
    <td>Participant unaware that browser window has opened “behind” player </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>401</td>
    <td>Choppy video noted </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Right click incongruous with TOC’s explorer window feel </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Colour selection boxes are confusing </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Right click does not make sense </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Should also be annotation quick setting </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>Video shouldn’t start on its own </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>301</td>
    <td>TOC icons are confusing </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>Video covers captions placed in top right </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User does not like alternative clicking required for links and navigation 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>At first user not able to tell if click on TOC has advanced video </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>User notes inconsistent language between caption and transcript labels 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>300</td>
    <td>TOC icons not intuitive to participant </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>User confuses “select” with save </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>Caption font changes colour regardless of settings </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>User places captions on top of annotation but does not realize it until 
      17 minutes have elapsed </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>User disables annotations even though he actually wants to view them. 
    </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>400</td>
    <td>Participant wants to change caption setting and does not realize he is 
      on annotation tab </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>500</td>
    <td>User does not like right click </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>Captions have to be switched to none and then on again in the quick settings 
      for the changes to take effect </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>502</td>
    <td>User wants larger screen area for player </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Video is choppy/flickers--distracting </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>Too much black space around video—looks unbalanced </td>
  </tr>
  <tr> 
    <td>&nbsp;</td>
    <td>501</td>
    <td>User finds language not intuitive: didactic, verbatim, author settings</td>
  </tr>
</table>
<a name="au_eval"></a><p><i>Authoring Tool Evaluation</i></p>
<p><font size="-1">October 8, 2002.</font></p>
<table border="1">
  <tr class="heading">
    <td>Issues</td>
    <td>Suggestion</td>
    <td>Priority</td>
    <td>Responsibilities</td>
  </tr>
  <tr>
    <td>LOR Location prompt </td>
    <td>It would be really nice if we could just hardcode this for the trial especially 
      if the web-based one will not require a pointer to the repository. Or at 
      least have the explorer point to the AT folder so that less navigating is 
      required.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Meta Data of existing learning objects </td>
    <td>In the trial version it will be best if all learning objects have relevant 
      titles</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Insert Caption from repository: Type and Language prompt </td>
    <td>It surprised me that I was prompted about the type and language of a pre-made 
      caption track. Is it meant to be informative or do you really think that 
      it is appropriate to change the type at this point? Information about the 
      track is already available at the selection point so having the other window 
      pop up seems redundant and scary for Ms. Smith.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Insert caption/annotation from repository does not actually work (the 
      rest of them are fine) </td>
    <td>Probably this problem is unique to my set-up but I’m telling you just 
      in case (and I did do the “replace” thing although it was not obvious that 
      it did anything)</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Insert New needs an escape hatch on dialogue boxes </td>
    <td>Include a cancel button on insert new dialogue boxes. Hitting x still 
      results in a track being inserted </td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Right click menu </td>
    <td>It would be a nice touch to have right click access to the edit menu on 
      the track title bar.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Save presentation</td>
    <td>Where the heck does it go? OK, I found this information in the meta data 
      and have a gripe about that too. The save function should indicate where 
      the save is happening and provide opportunity to cancel the operation and 
      to change the folder location. Creation of a new folder at this point is 
      standard and should be available as well.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Presentation Location </td>
    <td>I used the location but added a non-existent file and a new file name 
      then hit close and then clicked save all. No error messages, no warnings 
      and the thing saved where it wanted to with the name it wanted in the first 
      place. A browse and create new folder function here would be excellent or 
      remove altogether and leave location information for the save function. 
      I guess the whole thing might be complicated by the fact it will be web-based 
      and I am treating it like it is not but even still I think following the 
      typical save set-up for a local application will make the whole thing more 
      intuitive. The most important thing, I think, is that the location information 
      be added to the save function in the form of a dialogue even if it just 
      shows the location from the meta-data without opportunity to change it there. 
      There should always be a cancel though.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Edit meta-data when track not selected does not prompt for track selection 
    </td>
    <td>Add a Please select a track prompt</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Time setting could be confusing </td>
    <td>Consider adding a heading above the setting box that shows hh:mm:ss.0 
      or something like that</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Dialogue boxes for insert from LOR do not show up on task bar and are 
      not always on top of window yet they lock the AT if they are not completed 
    </td>
    <td>Have dialogue always on top or on task bar so that if it is accidentally 
      buried under another application window there is a hint about what the problem 
      is when the AT won’t work.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>Some language is techie-talk</td>
    <td>Ms. Smith would probably rather know the new style will be the same as 
      the old style except where she makes changes. Parent and inherit are not 
      used in this way by non-developers and may be confusing.</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</table>
<p>All things told, I found using the AT OK.  The dialogue boxes for meta-data seemed complicated and could have the opposite of their intended effect: users may feel overwhelmed and not enter any information rather than provide the detailed information needed to make a system like this work. I would like a less technical feeling dialogue in this area or option to have a guided walk through the meta-data inputs.  Perhaps this is where training and documentation come in as a factor.  I liked how easily I could manipulate blocks within the track and found that it was a simple task to add new tracks and tracks from the repository (this comment excludes the meta-data dialogues).</p>
<p align="right"> <a href="canarie_report.html"> <img src="img/back.gif" width="14" height="12" alt="back"></a>&nbsp;&nbsp;&nbsp; 
  <a href="append_b.html"> <img src="img/nxt.gif" width="14" height="12" alt="next"></a> 
</body>
</html>
